{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 94, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/KOMPYUTER_01/v0-nexa-gpt-development/app/api/chat/route.ts"],"sourcesContent":["import { GoogleGenerativeAI } from \"@google/generative-ai\"\r\nimport { Groq } from \"groq-sdk\"\r\n\r\nconst genAI = new GoogleGenerativeAI(process.env.GOOGLE_AI_API_KEY || \"\")\r\nconst groq = new Groq({ apiKey: process.env.GROQ_API_KEY })\r\n\r\nexport async function POST(req: Request) {\r\n  try {\r\n    const { messages, systemPrompt, images, useGroq = false } = await req.json()\r\n\r\n    /* =========================\r\n       GROQ (text only)\r\n    ========================== */\r\n    if (useGroq && (!images || images.length === 0)) {\r\n      const completion = await groq.chat.completions.create({\r\n        model: \"llama-3.3-70b-versatile\",\r\n        messages: [\r\n          {\r\n            role: \"system\",\r\n            content: systemPrompt || \"Sen NexaGPT – foydali va professional AI yordamchisan.\",\r\n          },\r\n          ...messages,\r\n        ],\r\n        temperature: 0.7,\r\n        max_tokens: 4096,\r\n        stream: true,\r\n      })\r\n\r\n      const encoder = new TextEncoder()\r\n\r\n      const stream = new ReadableStream({\r\n        async start(controller) {\r\n          try {\r\n            for await (const chunk of completion) {\r\n              const content = chunk.choices[0]?.delta?.content\r\n              if (content) {\r\n                controller.enqueue(\r\n                  encoder.encode(`data: ${JSON.stringify({ content })}\\n\\n`)\r\n                )\r\n              }\r\n            }\r\n            controller.enqueue(encoder.encode(\"data: [DONE]\\n\\n\"))\r\n            controller.close()\r\n          } catch (e) {\r\n            controller.error(e)\r\n          }\r\n        },\r\n      })\r\n\r\n      return new Response(stream, {\r\n        headers: {\r\n          \"Content-Type\": \"text/event-stream\",\r\n          \"Cache-Control\": \"no-cache\",\r\n          Connection: \"keep-alive\",\r\n        },\r\n      })\r\n    }\r\n\r\n    /* =========================\r\n       GEMINI\r\n    ========================== */\r\n    const model = genAI.getGenerativeModel({\r\n      model: \"gemini-2.5-flash\",\r\n      systemInstruction: systemPrompt ||\r\n        \"Sen NexaGPT – foydali va professional AI yordamchisan. Markdown formatida yoz.\",\r\n      safetySettings: [\r\n        { category: \"HARM_CATEGORY_HARASSMENT\", threshold: \"BLOCK_NONE\" },\r\n        { category: \"HARM_CATEGORY_HATE_SPEECH\", threshold: \"BLOCK_NONE\" },\r\n        { category: \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold: \"BLOCK_NONE\" },\r\n        { category: \"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold: \"BLOCK_NONE\" },\r\n      ],\r\n    })\r\n\r\n    const history = messages.slice(0, -1).map((m: any) => ({\r\n      role: m.role === \"assistant\" ? \"model\" : \"user\",\r\n      parts: [{ text: m.content }],\r\n    }))\r\n\r\n    const chat = model.startChat({\r\n      history,\r\n      generationConfig: {\r\n        temperature: 0.7,\r\n        maxOutputTokens: 8192,\r\n      },\r\n    })\r\n\r\n    const last = messages[messages.length - 1]\r\n\r\n    let parts: any[] = [{ text: last.content }]\r\n\r\n    if (images?.length) {\r\n      parts = [\r\n        { text: last.content },\r\n        ...images.map((img: string) => {\r\n          const base64 = img.split(\",\")[1] ?? img\r\n          const mimeType =\r\n            img.startsWith(\"data:image/png\") ? \"image/png\" : \"image/jpeg\"\r\n\r\n          return {\r\n            inlineData: { data: base64, mimeType },\r\n          }\r\n        }),\r\n      ]\r\n    }\r\n\r\n    const result = await chat.sendMessageStream(parts)\r\n\r\n    const encoder = new TextEncoder()\r\n\r\n    const stream = new ReadableStream({\r\n      async start(controller) {\r\n        try {\r\n          for await (const chunk of result.stream) {\r\n            const text = chunk.text()\r\n            if (text && text.trim()) {\r\n              controller.enqueue(\r\n                encoder.encode(`data: ${JSON.stringify({ content: text })}\\n\\n`)\r\n              )\r\n            }\r\n          }\r\n          controller.enqueue(encoder.encode(\"data: [DONE]\\n\\n\"))\r\n          controller.close()\r\n        } catch (e) {\r\n          controller.error(e)\r\n        }\r\n      },\r\n    })\r\n\r\n    return new Response(stream, {\r\n      headers: {\r\n        \"Content-Type\": \"text/event-stream\",\r\n        \"Cache-Control\": \"no-cache\",\r\n        Connection: \"keep-alive\",\r\n      },\r\n    })\r\n  } catch (error: any) {\r\n    return new Response(\r\n      JSON.stringify({\r\n        error: \"Failed to generate response\",\r\n        details: error?.message || \"Unknown error\",\r\n      }),\r\n      { status: 500 }\r\n    )\r\n  }\r\n}\r\n"],"names":[],"mappings":";;;;AAAA;AACA;;;AAEA,MAAM,QAAQ,IAAI,sLAAkB,CAAC,QAAQ,GAAG,CAAC,iBAAiB,IAAI;AACtE,MAAM,OAAO,IAAI,+JAAI,CAAC;IAAE,QAAQ,QAAQ,GAAG,CAAC,YAAY;AAAC;AAElD,eAAe,KAAK,GAAY;IACrC,IAAI;QACF,MAAM,EAAE,QAAQ,EAAE,YAAY,EAAE,MAAM,EAAE,UAAU,KAAK,EAAE,GAAG,MAAM,IAAI,IAAI;QAE1E;;+BAE2B,GAC3B,IAAI,WAAW,CAAC,CAAC,UAAU,OAAO,MAAM,KAAK,CAAC,GAAG;YAC/C,MAAM,aAAa,MAAM,KAAK,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;gBACpD,OAAO;gBACP,UAAU;oBACR;wBACE,MAAM;wBACN,SAAS,gBAAgB;oBAC3B;uBACG;iBACJ;gBACD,aAAa;gBACb,YAAY;gBACZ,QAAQ;YACV;YAEA,MAAM,UAAU,IAAI;YAEpB,MAAM,SAAS,IAAI,eAAe;gBAChC,MAAM,OAAM,UAAU;oBACpB,IAAI;wBACF,WAAW,MAAM,SAAS,WAAY;4BACpC,MAAM,UAAU,MAAM,OAAO,CAAC,EAAE,EAAE,OAAO;4BACzC,IAAI,SAAS;gCACX,WAAW,OAAO,CAChB,QAAQ,MAAM,CAAC,CAAC,MAAM,EAAE,KAAK,SAAS,CAAC;oCAAE;gCAAQ,GAAG,IAAI,CAAC;4BAE7D;wBACF;wBACA,WAAW,OAAO,CAAC,QAAQ,MAAM,CAAC;wBAClC,WAAW,KAAK;oBAClB,EAAE,OAAO,GAAG;wBACV,WAAW,KAAK,CAAC;oBACnB;gBACF;YACF;YAEA,OAAO,IAAI,SAAS,QAAQ;gBAC1B,SAAS;oBACP,gBAAgB;oBAChB,iBAAiB;oBACjB,YAAY;gBACd;YACF;QACF;QAEA;;+BAE2B,GAC3B,MAAM,QAAQ,MAAM,kBAAkB,CAAC;YACrC,OAAO;YACP,mBAAmB,gBACjB;YACF,gBAAgB;gBACd;oBAAE,UAAU;oBAA4B,WAAW;gBAAa;gBAChE;oBAAE,UAAU;oBAA6B,WAAW;gBAAa;gBACjE;oBAAE,UAAU;oBAAmC,WAAW;gBAAa;gBACvE;oBAAE,UAAU;oBAAmC,WAAW;gBAAa;aACxE;QACH;QAEA,MAAM,UAAU,SAAS,KAAK,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,CAAC,IAAW,CAAC;gBACrD,MAAM,EAAE,IAAI,KAAK,cAAc,UAAU;gBACzC,OAAO;oBAAC;wBAAE,MAAM,EAAE,OAAO;oBAAC;iBAAE;YAC9B,CAAC;QAED,MAAM,OAAO,MAAM,SAAS,CAAC;YAC3B;YACA,kBAAkB;gBAChB,aAAa;gBACb,iBAAiB;YACnB;QACF;QAEA,MAAM,OAAO,QAAQ,CAAC,SAAS,MAAM,GAAG,EAAE;QAE1C,IAAI,QAAe;YAAC;gBAAE,MAAM,KAAK,OAAO;YAAC;SAAE;QAE3C,IAAI,QAAQ,QAAQ;YAClB,QAAQ;gBACN;oBAAE,MAAM,KAAK,OAAO;gBAAC;mBAClB,OAAO,GAAG,CAAC,CAAC;oBACb,MAAM,SAAS,IAAI,KAAK,CAAC,IAAI,CAAC,EAAE,IAAI;oBACpC,MAAM,WACJ,IAAI,UAAU,CAAC,oBAAoB,cAAc;oBAEnD,OAAO;wBACL,YAAY;4BAAE,MAAM;4BAAQ;wBAAS;oBACvC;gBACF;aACD;QACH;QAEA,MAAM,SAAS,MAAM,KAAK,iBAAiB,CAAC;QAE5C,MAAM,UAAU,IAAI;QAEpB,MAAM,SAAS,IAAI,eAAe;YAChC,MAAM,OAAM,UAAU;gBACpB,IAAI;oBACF,WAAW,MAAM,SAAS,OAAO,MAAM,CAAE;wBACvC,MAAM,OAAO,MAAM,IAAI;wBACvB,IAAI,QAAQ,KAAK,IAAI,IAAI;4BACvB,WAAW,OAAO,CAChB,QAAQ,MAAM,CAAC,CAAC,MAAM,EAAE,KAAK,SAAS,CAAC;gCAAE,SAAS;4BAAK,GAAG,IAAI,CAAC;wBAEnE;oBACF;oBACA,WAAW,OAAO,CAAC,QAAQ,MAAM,CAAC;oBAClC,WAAW,KAAK;gBAClB,EAAE,OAAO,GAAG;oBACV,WAAW,KAAK,CAAC;gBACnB;YACF;QACF;QAEA,OAAO,IAAI,SAAS,QAAQ;YAC1B,SAAS;gBACP,gBAAgB;gBAChB,iBAAiB;gBACjB,YAAY;YACd;QACF;IACF,EAAE,OAAO,OAAY;QACnB,OAAO,IAAI,SACT,KAAK,SAAS,CAAC;YACb,OAAO;YACP,SAAS,OAAO,WAAW;QAC7B,IACA;YAAE,QAAQ;QAAI;IAElB;AACF"}}]
}